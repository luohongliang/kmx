{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from notebook, using serial load function.\n",
      "[20, 40, 60, 80, 100]\n",
      "/home/hongliang/inpho/kmx/models/kmx-freq5-freq5-N2523342-LDA-K{0}-document-1000.npz\n",
      "Loading LDA data from /home/hongliang/inpho/kmx/models/kmx-freq5-freq5-N2523342-LDA-K20-document-1000.npz\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:UTF-8 -*-\n",
    "\n",
    "    \n",
    "from corpus import *\n",
    "from vsm import *\n",
    "from vsm.spatial import KL_div\n",
    "\n",
    "\n",
    "k = topic_range[0]\n",
    "v = lda_v[k]\n",
    "c.words\n",
    "\n",
    "# train the model and create a TfViewer object\n",
    "tf = TF(c, context_type)\n",
    "tf.train()\n",
    "tf_v = TfViewer(c, tf)\n",
    "\n",
    "# print the most frequent terms in the document\n",
    "# remember that IPython automatically prints the last cell of a document\n",
    "tf_v.coll_freqs()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#v.topics()\n",
    "\n",
    "#v.doc_topics(v.labels[:3])\n",
    "\n",
    "\n",
    "#v.dist(v.labels[0], v.labels[1])\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import matplotlib.font_manager as fm\n",
    "myfont = fm.FontProperties(fname='/home/hongliang/Downloads/msyh.ttf/msyh.ttf')\n",
    "import sys\n",
    "reload(sys)\n",
    "kongzi = []\n",
    "mengzi = []\n",
    "xunzi =[]\n",
    "\n",
    "count = 0\n",
    "for label in v.labels[:]:\n",
    "    if '孟子' in label:\n",
    "        mengzi.append(count)\n",
    "    elif '论语' in label:\n",
    "        kongzi.append(count)\n",
    "    elif '荀子' in label:\n",
    "        xunzi.append(count)\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity(c1,c2):\n",
    "    A = np.zeros((len(c1),len(c2)))\n",
    "    for m in range(len(c1)):\n",
    "        for n in range(len(c2)):\n",
    "            A[m][n]= v.dist(v.labels[c1[m]],v.labels[c2[n]]) \n",
    "    print \"while k quals\",k,',','JSD goes',np.mean(A)\n",
    "    return np.mean(A)\n",
    "\n",
    "def kl_similarity(c1,c2):\n",
    "    A = np.zeros((len(c1),len(c2)))\n",
    "    for m in range(len(c1)):\n",
    "        for n in range(len(c2)):\n",
    "            A[m][n]= v.dist(v.labels[c1[m]],v.labels[c2[n]], dist_fn=KL_div) \n",
    "    print \"while k quals\",k,',','first to second KLD goes',np.mean(A)\n",
    "    \n",
    "    B = np.zeros((len(c1),len(c2)))\n",
    "    for m in range(len(c1)):\n",
    "        for n in range(len(c2)):\n",
    "            B[m][n]= v.dist(v.labels[c2[n]],v.labels[c1[m]], dist_fn=KL_div) \n",
    "    print \"while k quals\",k,',','second to first KLD goes',np.mean(B)\n",
    "        \n",
    "    \n",
    "    \n",
    "    return np.mean(A),np.mean(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perplexity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6e477d91a175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_topic_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mperplexity_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mperplexity_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perplexity' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    k = topic_range[i]\n",
    "    v = lda_v[k]\n",
    "    print 'kongzi mengzi JSD'\n",
    "    similarity(kongzi,mengzi)\n",
    "    print 'kongzi xunzi JSD'\n",
    "    similarity(kongzi,xunzi)\n",
    "    print 'xunzi mengzi JSD'\n",
    "    similarity(xunzi,mengzi)\n",
    "    print 'kongzi mengzi KLD'\n",
    "    kl_similarity(kongzi,mengzi)\n",
    "    print 'kongzi xunzi KLD'\n",
    "    kl_similarity(kongzi,xunzi)\n",
    "    print 'xunzi mengzi KLD'\n",
    "    kl_similarity(xunzi,mengzi)\n",
    "    \n",
    "for i in range(5):\n",
    "    k = topic_range[i]\n",
    "    v = lda_v[k]    \n",
    "    perplexity_num = []\n",
    "    documents = v.corpus.view_contexts('document')\n",
    "    for doc_id,corpus in zip(all_ids,documents):\n",
    "        theta = v.doc_topic_matrix(doc_id)\n",
    "        perplexity_num.append(perplexity(theta,corpus,v))\n",
    "    perplexity_num = np.array(perplexity_num)\n",
    "    print k\n",
    "    print np.mean(perplexity_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original with bug \n",
    "TypeError: invalid type promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid type promotion",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09bda6db90c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-09bda6db90c6>\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(theta, corpus, v)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type promotion"
     ]
    }
   ],
   "source": [
    "from corpus import *\n",
    "import numpy as np\n",
    "\n",
    "def perplexity(theta, corpus, v):\n",
    "    a = (v.phi[corpus] * theta).sum(axis=1)\n",
    "    a = np.log2(a).sum()\n",
    "    return a / len(corpus)\n",
    "\n",
    "v = lda_v[80]\n",
    "\n",
    "# v.aggregate_doc_topics returns an ndarray instead of just values.\n",
    "theta = v.aggregate_doc_topics(all_ids)\n",
    "# theta = theta[np.argsort(theta['i'])]\n",
    "# theta = np.array(theta['value'])\n",
    "print theta\n",
    "corpus = v.corpus.corpus\n",
    "P = perplexity(theta, corpus, v)\n",
    "print P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import *\n",
    "import numpy as np\n",
    "\n",
    "def perplexity(theta, corpus, v):\n",
    "   a = (v.phi[corpus] * theta).sum(axis=1)\n",
    "   a = np.log2(a).sum()\n",
    "   return a / len(corpus)\n",
    "\n",
    "v = lda_v[80]\n",
    "theta = v.aggregate_doc_topics(all_ids)\n",
    "TMP = []\n",
    "for a in theta:\n",
    "   TMP.append(a[1]) \n",
    "theta = np.array(TMP)\n",
    "print theta\n",
    "corpus = v.corpus.corpus\n",
    "P = perplexity(theta, corpus, v)\n",
    "print P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## each to whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perplexity(theta, corpus, v):\n",
    "    a = (v.phi[corpus] * theta).sum(axis=1)\n",
    "    a = np.log2(a).sum()\n",
    "    return a / len(corpus)\n",
    "\n",
    "v = lda_v[80]    \n",
    "perplexity_num = []\n",
    "theta_all = []\n",
    "documents = v.corpus.view_contexts('document')\n",
    "for doc_id,corpus in zip(all_ids,documents):\n",
    "    theta = v.doc_topic_matrix(doc_id)\n",
    "    print theta\n",
    "    theta_all.append(theta)\n",
    "    perplexity_num.append(perplexity(theta,corpus,v))\n",
    "perplexity_num = np.array(perplexity_num)\n",
    "theta_all = np.array(theta_all)\n",
    "print 'each document way',np.mean(perplexity_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaimie's Final method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import *\n",
    "import numpy as np\n",
    "\n",
    "def perplexity(theta, corpus, v):\n",
    "    a = (v.phi[corpus] * theta).sum(axis=1)\n",
    "    a = np.log2(a).sum()\n",
    "    return a / len(corpus)\n",
    "\n",
    "v = lda_v[80]\n",
    "corpus = v.corpus.corpus\n",
    "\n",
    "# v.aggregate_doc_topics returns an ndarray instead of just values.\n",
    "theta = v.aggregate_doc_topics(all_ids)\n",
    "print 'theta 1 step',theta\n",
    "theta = theta[np.argsort(theta['i'])]\n",
    "print 'theat2 step',theta\n",
    "theta = np.array(theta['value'])\n",
    "print 'theta3 step',theta\n",
    "\n",
    "P = perplexity(theta, corpus, v)\n",
    "print 'whole corpus',P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
